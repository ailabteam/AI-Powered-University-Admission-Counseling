# app.py
import os
# Äáº·t biáº¿n mÃ´i trÆ°á»ng NGAY Láº¬P Tá»¨C, trÆ°á»›c khi torch Ä‘Æ°á»£c import
# Äiá»u nÃ y Ä‘áº£m báº£o toÃ n bá»™ á»©ng dá»¥ng chá»‰ sá»­ dá»¥ng GPU 1
os.environ["CUDA_VISIBLE_DEVICES"] = "1" 

import streamlit as st
from src.pipeline import QAPipeline

# --- Page Configuration ---
st.set_page_config(
    page_title="Mentor AI - TÆ° váº¥n Tuyá»ƒn sinh",
    page_icon="ğŸ“",
    layout="wide"
)

# --- State Management & Caching ---
# Sá»­ dá»¥ng @st.cache_resource Ä‘á»ƒ khá»Ÿi táº¡o pipeline má»™t láº§n vÃ  tÃ¡i sá»­ dá»¥ng
@st.cache_resource
def load_pipeline():
    """Táº£i pipeline vÃ  cache láº¡i."""
    print("--- First time initialization: Loading QA Pipeline... ---")
    return QAPipeline()

# --- UI Components ---
st.title("ğŸ“ Mentor AI - Trá»£ lÃ½ TÆ° váº¥n Tuyá»ƒn sinh ÄH BÃ¡ch khoa ÄÃ  Náºµng")
st.markdown("""
ChÃ o má»«ng báº¡n! TÃ´i lÃ  Mentor AI, trá»£ lÃ½ áº£o sáºµn sÃ ng giáº£i Ä‘Ã¡p cÃ¡c tháº¯c máº¯c vá» tuyá»ƒn sinh cá»§a TrÆ°á»ng. 
HÃ£y Ä‘áº·t cÃ¢u há»i cá»§a báº¡n vÃ o khung chat bÃªn dÆ°á»›i nhÃ©.
""")

# Táº£i pipeline tá»« cache
try:
    pipeline = load_pipeline()
except Exception as e:
    st.error(f"Lá»—i khá»Ÿi táº¡o há»‡ thá»‘ng AI: {e}")
    st.stop()

# Khá»Ÿi táº¡o lá»‹ch sá»­ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hiá»ƒn thá»‹ cÃ¡c tin nháº¯n cÅ©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Nháº­n input tá»« ngÆ°á»i dÃ¹ng
if prompt := st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n vá» tuyá»ƒn sinh..."):
    # Hiá»ƒn thá»‹ tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Táº¡o vÃ  hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i cá»§a trá»£ lÃ½ AI
    with st.chat_message("assistant"):
        with st.spinner("Mentor AI Ä‘ang suy nghÄ©..."):
            result_dict = pipeline.ask(prompt)
            response = result_dict.get("answer", "Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ khi táº¡o cÃ¢u tráº£ lá»i.")
            st.markdown(response)
    
    # ThÃªm cÃ¢u tráº£ lá»i vÃ o lá»‹ch sá»­ chat
    st.session_state.messages.append({"role": "assistant", "content": response})
